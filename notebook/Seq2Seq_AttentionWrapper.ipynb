{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, is_target = False, max_vocab_size = None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "    \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['GO'] = 0\n",
    "        vocab[' PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab[' PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([9, 3, 6, 4, 21, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 10, 21, 23, 18, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab = enc_vocab, max_sentence_length = enc_sentence_length, is_target = False ):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens]+ [1]*pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens]+ [0]*pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    #Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    attn_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    #Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    #Tokens\n",
    "    start_token = 0 # GO\n",
    "    end_token = 1 # PAD\n",
    "    \n",
    "    #checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir_seq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "        \n",
    "        #Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.cell = config.cell\n",
    "        self.attn_size = config.attn_size\n",
    "        \n",
    "        #Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Token\n",
    "        self.start_token = config.start_token\n",
    "        self.end_token = config.end_token\n",
    "        \n",
    "        #checkpoint path\n",
    "        self.ckpt_path = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholder(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape = [None, enc_sentence_length],\n",
    "            name = 'input_sentences'\n",
    "        )\n",
    "        self.enc_seq_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape = [None,],\n",
    "            name = 'input_seq_length'\n",
    "        )\n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(tf.int32,\n",
    "                                            shape=[None, dec_sentence_length+1],\n",
    "                                            name = 'target_sentence')\n",
    "            self.dec_sequence_length = tf.placeholder(tf.int32,\n",
    "                                                     shape=[None,],\n",
    "                                                     name = 'target_seq_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable(\n",
    "                    'embedding',\n",
    "                    initializer = tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype = tf.float32\n",
    "                )\n",
    "        #[Batch_size, enc_seq_length, embedding_size]\n",
    "        enc_emb_inputs = tf.nn.embedding_lookup(self.enc_Wemb,self.enc_inputs,\n",
    "                                                name = 'emb_inputs'\n",
    "                                               )\n",
    "        enc_cell = self.cell(self.hidden_size)\n",
    "        # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "        # enc_last_state: [batch_size x embedding_size]\n",
    "        self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "            cell = enc_cell,\n",
    "            inputs = enc_emb_inputs,\n",
    "            sequence_length = self.enc_seq_length,\n",
    "            time_major = False,\n",
    "            dtype = tf.float32\n",
    "        )\n",
    "\n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wdec = tf.get_variable(\n",
    "                    'embedding',\n",
    "                    initializer = tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype = tf.float32\n",
    "                )\n",
    "        dec_cell = self.cell(self.hidden_size)\n",
    "        # get dynamic batch_size\n",
    "        batch_size = tf.shape(self.enc_inputs)[0]\n",
    "        \n",
    "        attn_mech = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units = self.attn_size,\n",
    "            memory = self.enc_outputs,\n",
    "            memory_sequence_length=self.enc_seq_length,\n",
    "            name='LuongAttention'\n",
    "        )\n",
    "        \n",
    "        dec_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            cell = dec_cell,\n",
    "            attention_mechanism = attn_mech,\n",
    "            attention_layer_size = self.attn_size,\n",
    "            name='Attention_Wrapper'\n",
    "        )\n",
    "        \n",
    "        #initial state\n",
    "        initial_state = dec_cell.zero_state(dtype=tf.float32, batch_size = batch_size)\n",
    "        \n",
    "#             initial_state = tf.contrib.seq2seq.AttentionWrapperState(\n",
    "#                 cell_state=self.enc_last_state,\n",
    "#                 attention=_zero_state_tensors(self.attn_size, batch_size, tf.float32),\n",
    "#                  time=0, alignments=(), \n",
    "#                 alignment_history=()\n",
    "#             )\n",
    "\n",
    "        #output project layer\n",
    "        output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "\n",
    "        if self.mode == 'training':\n",
    "\n",
    "            # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "            max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "            dec_emb_inputs = tf.nn.embedding_lookup(self.dec_Wdec, self.dec_inputs,\n",
    "                                                   name = 'dec_inputs')\n",
    "            \"\"\"\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(dec_emb_inputs,\n",
    "                                                               sequence_length=self.dec_sequence_length+1,\n",
    "                                                               name = 'training_helper')\n",
    "            \"\"\"\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                dec_emb_inputs,                                                                   \n",
    "                sequence_length=self.dec_sequence_length+1,\n",
    "                time_major = False,\n",
    "                name='trainghelper'\n",
    "            )\n",
    "\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                              training_helper,\n",
    "                                                              initial_state = initial_state,\n",
    "                                                              output_layer=output_layer)\n",
    "\n",
    "            train_dec_outputs,train_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                                                       output_time_major=False,\n",
    "                                                                                       impute_finished=True,\n",
    "                                                                                       maximum_iterations=max_dec_len)\n",
    "            # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "            # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "            # dec_outputs.sample_id [batch_size], tf.int32\n",
    "            # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "            logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "\n",
    "            # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "            targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "            print('max_dec_len',max_dec_len)\n",
    "            # masks: [batch_size x max_dec_len]\n",
    "            # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "            masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "\n",
    "            # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "            # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "            self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                logits=logits,\n",
    "                targets=targets,\n",
    "                weights=masks,\n",
    "                name='batch-loss'\n",
    "            )\n",
    "            # prediction sample for validation\n",
    "            self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "            # List of training variables\n",
    "            # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "        elif self.mode == 'inference':\n",
    "\n",
    "            # batch_size = tf.shape(self.enc_inputs)[0:1]\n",
    "            start_tokens = tf.tile(tf.constant([self.start_token], dtype=tf.int32),[batch_size], name='start_tokens')\n",
    "\n",
    "            inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                embedding=self.dec_Wdec,\n",
    "                start_tokens=start_tokens,\n",
    "                end_token=self.end_token\n",
    "            )\n",
    "            inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                dec_cell,\n",
    "                helper=inference_helper,\n",
    "                initial_state=initial_state,\n",
    "                output_layer=output_layer\n",
    "            )\n",
    "\n",
    "            infer_dec_outputs, infer_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                inference_decoder,\n",
    "                output_time_major = False,\n",
    "                impute_finished =True,\n",
    "                maximum_iterations = dec_sentence_length\n",
    "            )\n",
    "\n",
    "            # [batch_size x dec_sentence_length], tf.int32\n",
    "            self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "            # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "\n",
    "            # List of training variables\n",
    "            # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "\n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print('Saving model at {0}'.format(save_path))\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "\n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "\n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir = self.ckpt_path,\n",
    "            graph = tf.get_default_graph()\n",
    "        )\n",
    "\n",
    "    def build(self):\n",
    "        self.add_placeholder()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "          load_ckpt=None, save_path=None):\n",
    "\n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "\n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "\n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "\n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_seq_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "\n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print('\\tInput:', input_sent)\n",
    "                        print('prediction',pred)\n",
    "                        print('\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print('\\tTarget:', target_sent)\n",
    "                print('\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "\n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "\n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "\n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "\n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "\n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_seq_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_dec_len Tensor(\"max_dec_len:0\", shape=(), dtype=int32)\n",
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = seq2seqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = seq2seqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_dec_len Tensor(\"max_dec_len:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/801 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: Hi What is your name?\n",
      "prediction [ 4 21 21 21 21 21  0]\n",
      "\tPrediction: ! this this this this this GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "prediction [ 4 21 21 21 17 17 17]\n",
      "\tPrediction: ! this this this study study study\n",
      "\tTarget: Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "prediction [ 4 21 17 17 17]\n",
      "\tPrediction: ! this study study study\n",
      "\tTarget: I like Python.\n",
      "\tInput: See you later.\n",
      "prediction [ 4 21 21 21  0]\n",
      "\tPrediction: ! this this this GO\n",
      "\tTarget: Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "prediction [ 4 21 14 17 17 17 17 17 17]\n",
      "\tPrediction: ! this please study study study study study study\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "prediction [ 4 17 17 17 17 17  0  0  0]\n",
      "\tPrediction: ! study study study study study GO GO GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "prediction [ 4  4  4 21]\n",
      "\tPrediction: ! ! ! this\n",
      "\tTarget: Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "prediction [ 4 21 21 21]\n",
      "\tPrediction: ! this this this\n",
      "\tTarget: Leffe brown!\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████▉                                        | 400/801 [00:09<00:09, 42.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: Hi What is your name?\n",
      "prediction [ 0 10 21 23 18  2  0]\n",
      "\tPrediction: GO Hi this is Jaemin . GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "prediction [ 0 28 29  9 22 26  4]\n",
      "\tPrediction: GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "prediction [ 0  3 25 19  2]\n",
      "\tPrediction: GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\tInput: See you later.\n",
      "prediction [0 5 5 2 0]\n",
      "\tPrediction: GO Bye Bye . GO\n",
      "\tTarget: Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "prediction [ 0  3 20 27  6 15 12 11  2]\n",
      "\tPrediction: GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "prediction [ 0  3 17 24 13  2  0  0  0]\n",
      "\tPrediction: GO I study industrial engineering . GO GO GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "prediction [ 0  7 14  4]\n",
      "\tPrediction: GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "prediction [ 0 16  8  4]\n",
      "\tPrediction: GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 798/801 [00:18<00:00, 42.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: Hi What is your name?\n",
      "prediction [ 0 10 21 23 18  2  0]\n",
      "\tPrediction: GO Hi this is Jaemin . GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "prediction [ 0 28 29  9 22 26  4]\n",
      "\tPrediction: GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "prediction [ 0  3 25 19  2]\n",
      "\tPrediction: GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\tInput: See you later.\n",
      "prediction [0 5 5 2 0]\n",
      "\tPrediction: GO Bye Bye . GO\n",
      "\tTarget: Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "prediction [ 0  3 20 27  6 15 12 11  2]\n",
      "\tPrediction: GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "prediction [ 0  3 17 24 13  2  0  0  0]\n",
      "\tPrediction: GO I study industrial engineering . GO GO GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "prediction [ 0  7 14  4]\n",
      "\tPrediction: GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "prediction [ 0 16  8  4]\n",
      "\tPrediction: GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 801/801 [00:18<00:00, 42.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at ./ckpt_dir_seqepoch_801\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = seq2seqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_path+'epoch_'+str(model.n_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: GO Hi this is Jaemin . . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: GO Nice to meet you too ! ! ! !\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: GO I like Python Python . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: GO Bye Bye . . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: GO I live live in Seoul South South Korea .\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: GO Leffe brown ! ! ! . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: GO Beer please ! ! . . . . .\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: GO Leffe brown ! ! ! ! ! . .\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = seq2seqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_path+'epoch_'+str(model.n_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.randint(1, high=22, size=[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 13, 11,  1, 16,  9, 17,  6,  8,  5, 10, 10, 13,  7,  7, 16, 19,\n",
       "       15,  3, 18,  7, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x has shape [2, 3, 2]\n",
    "x = tf.constant([[[1., 2.], [3., 4. ], [5. , 6. ]],\n",
    "                 [[7., 8.], [9., 10.], [11., 12.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_1:0' shape=(2, 2) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.]],\n",
       "\n",
       "       [[ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  4.],\n",
       "       [ 9., 10.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1,:].eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.]],\n",
       "\n",
       "       [[7., 8.]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(x,[0,0,0],[-1,1,2]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.constant(np.reshape(test,(2,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.slice(y,[0,0],[-1,8]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, is_target = False, max_vocab_size = None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "    \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['GO'] = 0\n",
    "        vocab[' PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab[' PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([26, 3, 5, 6, 21, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 17, 16, 19, 6, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab = enc_vocab, max_sentence_length = enc_sentence_length, is_target = False ):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens]+ [1]*pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens]+ [0]*pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    #Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    #Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Sampling Probability\n",
    "    # with decay => 'Curriculumn Learning'\n",
    "    sampling_probability_list = np.linspace(start=0.0,\n",
    "                                            stop=1.0,\n",
    "                                            num=n_epoch,\n",
    "                                            dtype=np.float32\n",
    "                                           )\n",
    "    \n",
    "    #checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir_seq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "        \n",
    "        #Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        #Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Sampling Probability\n",
    "        self.sampling_probability_list = config.sampling_probability_list\n",
    "        \n",
    "        #checkpoint path\n",
    "        self.ckpt_path = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholder(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape = [None, enc_sentence_length],\n",
    "            name = 'input_sentences'\n",
    "        )\n",
    "        self.enc_seq_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape = [None,],\n",
    "            name = 'input_seq_length'\n",
    "        )\n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(tf.int32,\n",
    "                                            shape=[None, dec_sentence_length+1],\n",
    "                                            name = 'target_sentence')\n",
    "            self.dec_sequence_length = tf.placeholder(tf.int32,\n",
    "                                                     shape=[None,],\n",
    "                                                     name = 'target_seq_length')\n",
    "            self.sampling_probabilty = tf.placeholder(tf.float32,\n",
    "                                                     shape=[],\n",
    "                                                     name='sampling_probability')\n",
    "\n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable(\n",
    "                    'embedding',\n",
    "                    initializer = tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype = tf.float32\n",
    "                )\n",
    "        #[Batch_size, seq_length, embedding_size]\n",
    "        enc_emb_inputs = tf.nn.embedding_lookup(self.enc_Wemb,self.enc_inputs,\n",
    "                                                name = 'emb_inputs'\n",
    "                                               )\n",
    "        enc_cell = self.cell(self.hidden_size)\n",
    "        # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "        # enc_last_state: [batch_size x embedding_size]\n",
    "        enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "            cell = enc_cell,\n",
    "            inputs = enc_emb_inputs,\n",
    "            sequence_length = self.enc_seq_length,\n",
    "            time_major = False,\n",
    "            dtype = tf.float32\n",
    "        )\n",
    "\n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wdec = tf.get_variable(\n",
    "                    'embedding',\n",
    "                    initializer = tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype = tf.float32\n",
    "                )\n",
    "        dec_cell = self.cell(self.hidden_size)\n",
    "\n",
    "        #output project layer\n",
    "        output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "\n",
    "        if self.mode == 'training':\n",
    "\n",
    "            # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "            max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "            dec_emb_inputs = tf.nn.embedding_lookup(self.dec_Wdec, self.dec_inputs,\n",
    "                                                   name = 'dec_inputs')\n",
    "            \"\"\"\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(dec_emb_inputs,\n",
    "                                                               sequence_length=self.dec_sequence_length+1,\n",
    "                                                               name = 'training_helper')\n",
    "            \"\"\"\n",
    "            training_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(\n",
    "                dec_emb_inputs,                                                                   \n",
    "                sequence_length=self.dec_sequence_length+1,\n",
    "                embedding = self.dec_Wdec,\n",
    "                sampling_probability = self.sampling_probabilty,\n",
    "                time_major = False,\n",
    "                name='trainghelper'\n",
    "            )\n",
    "\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                              training_helper,\n",
    "                                                              initial_state = self.enc_last_state,\n",
    "                                                              output_layer=output_layer)\n",
    "\n",
    "            train_dec_outputs,train_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                                                       output_time_major=False,\n",
    "                                                                                       impute_finished=True,\n",
    "                                                                                       maximum_iterations=max_dec_len)\n",
    "            # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "            # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "            # dec_outputs.sample_id [batch_size], tf.int32\n",
    "            # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "            logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "\n",
    "            # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "            targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "            print('max_dec_len',max_dec_len)\n",
    "            # masks: [batch_size x max_dec_len]\n",
    "            # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "            masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "\n",
    "            # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "            # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "            self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                logits=logits,\n",
    "                targets=targets,\n",
    "                weights=masks,\n",
    "                name='batch-loss'\n",
    "            )\n",
    "            # prediction sample for validation\n",
    "            # some sample_id are overwritten with '-1's\n",
    "            self.valid_predictions = tf.argmax(logits,axis=2, name='valid_preds')\n",
    "\n",
    "            # List of training variables\n",
    "            # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "        elif self.mode == 'inference':\n",
    "\n",
    "            batch_size = tf.shape(self.enc_inputs)[0:1]\n",
    "            start_tokens = tf.zeros(batch_size, dtype=tf.int32)\n",
    "\n",
    "            inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                embedding=self.dec_Wdec,\n",
    "                start_tokens=start_tokens,\n",
    "                end_token=1\n",
    "            )\n",
    "            inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                dec_cell,\n",
    "                helper=inference_helper,\n",
    "                initial_state=self.enc_last_state,\n",
    "                output_layer=output_layer\n",
    "            )\n",
    "\n",
    "            infer_dec_outputs, infer_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                inference_decoder,\n",
    "                output_time_major = False,\n",
    "                impute_finished =True,\n",
    "                maximum_iterations = dec_sentence_length\n",
    "            )\n",
    "\n",
    "            # [batch_size x dec_sentence_length], tf.int32\n",
    "            self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "            # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "\n",
    "            # List of training variables\n",
    "            # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "\n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print('Saving model at {0}'.format(save_path))\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "\n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "\n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir = self.ckpt_path,\n",
    "            graph = tf.get_default_graph()\n",
    "        )\n",
    "\n",
    "    def build(self):\n",
    "        self.add_placeholder()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "          load_ckpt=None, save_path=None):\n",
    "\n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "\n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "\n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "\n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_seq_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                        self.sampling_probabilty: self.sampling_probability_list[epoch]\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "\n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print('\\tInput:', input_sent)\n",
    "                        print('prediction',pred)\n",
    "                        print('\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print('\\tTarget:', target_sent)\n",
    "                print('\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "\n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "\n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "\n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "\n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "\n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "\n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_seq_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_dec_len Tensor(\"max_dec_len:0\", shape=(), dtype=int32)\n",
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = seq2seqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = seq2seqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_dec_len Tensor(\"max_dec_len:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "  0%|                                                                                          | 0/801 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: Hi What is your name?\n",
      "prediction [11 11 11 17 17 17  0]\n",
      "\tPrediction: in in in Hi Hi Hi GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "prediction [ 8 11 17 17 17 17 28]\n",
      "\tPrediction: Leffe in Hi Hi Hi Hi too\n",
      "\tTarget: Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "prediction [ 8 11 15 29 29]\n",
      "\tPrediction: Leffe in study meet meet\n",
      "\tTarget: I like Python.\n",
      "\tInput: See you later.\n",
      "prediction [11 11 11 17  0]\n",
      "\tPrediction: in in in Hi GO\n",
      "\tTarget: Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "prediction [11 11 11 17 12 12 12 12 28]\n",
      "\tPrediction: in in in Hi to to to to too\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "prediction [ 8 11 17 28 17 28  0  0  0]\n",
      "\tPrediction: Leffe in Hi too Hi too GO GO GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "prediction [ 8 11 11 29]\n",
      "\tPrediction: Leffe in in meet\n",
      "\tTarget: Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "prediction [11 11 17 12]\n",
      "\tPrediction: in in Hi to\n",
      "\tTarget: Leffe brown!\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████▊                                        | 398/801 [00:15<00:15, 26.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: Hi What is your name?\n",
      "prediction [ 0 17 16 19  6  2  0]\n",
      "\tPrediction: GO Hi this is Jaemin . GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "prediction [ 0 13 12 29  7 28  4]\n",
      "\tPrediction: GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "prediction [ 0  3  9 20  2]\n",
      "\tPrediction: GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\tInput: See you later.\n",
      "prediction [0 5 5 2 0]\n",
      "\tPrediction: GO Bye Bye . GO\n",
      "\tTarget: Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "prediction [ 0  3 21 11 27 10 26 24  2]\n",
      "\tPrediction: GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "prediction [ 0  3 15 23 22  2  0  0  0]\n",
      "\tPrediction: GO I study industrial engineering . GO GO GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "prediction [ 0 14 18  4]\n",
      "\tPrediction: GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "prediction [ 0  8 25  4]\n",
      "\tPrediction: GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 798/801 [00:29<00:00, 26.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: Hi What is your name?\n",
      "prediction [ 0 17 16 19  6  2  0]\n",
      "\tPrediction: GO Hi this is Jaemin . GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "prediction [ 0 13 12 29  7 28  4]\n",
      "\tPrediction: GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "prediction [ 0  3  9 20  2]\n",
      "\tPrediction: GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\tInput: See you later.\n",
      "prediction [0 5 5 2 0]\n",
      "\tPrediction: GO Bye Bye . GO\n",
      "\tTarget: Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "prediction [ 0  3 21 11 27 10 26 24  2]\n",
      "\tPrediction: GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "prediction [ 0  3 15 23 22  2  0  0  0]\n",
      "\tPrediction: GO I study industrial engineering . GO GO GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "prediction [ 0 14 18  4]\n",
      "\tPrediction: GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "prediction [ 0  8 25  4]\n",
      "\tPrediction: GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 801/801 [00:30<00:00, 26.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at ./ckpt_dir_seqepoch_801\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = seq2seqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_path+'epoch_'+str(model.n_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3X9w5Ol9F/j3s5p2ttdJLDuekEwn/nFwJVeZIRYWh8PeHbHzQ+aIgxgf8YXkCIHDd/xxJL4gWEGKdYJTu4XIOVfH1R3m8quwCRvHQueQgBJYUyl8ce5mozWKf+gCBG/c4+AJXoXgaXZ7tM/9MZIsabr1Y0bdLXW/XlVTIz3fp7s/Go9dmXeez+cptdYAAAAAQC8PjLoAAAAAAM4v4REAAAAAfQmPAAAAAOhLeAQAAABAX8IjAAAAAPoSHgEAAADQl/AIAOAYpZR/VEr5zlHXAQAwCsIjAODcKqX8m1LKN4y6jlrrH6m1/sQg3ruU8qWllB8upTxTSvkPpZR/ufP9ywfxeQAApyU8AgAmWinl0gg/+0VJ/mmS1yZ5c5IvTfKHkvy7JP/ZPbzfyH4WAGB8CY8AgAuplPLNpZSnSylbpZT/u5Ty+/Y9e6SU8q9KKb9TSvl4KeWP73v2p0spHy6lvLuU8rkk79xZ++ellL9ZSnm2lPLrpZQ/su81/6yU8t/te/1Re19dSvnFnc/+J6WU/62U8t4+P8afSvKKJH+81vrxWusLtdbP1lr/eq3153ber5ZSfs++9//xUsq7dr7+ulLKp0spf7mU8ptJfqyU8olSyjfv23+plPJbpZTfv/P9G3b+vLZKKR8tpXzd/fznAACMP+ERAHDh7AQhP5rkv0/yZUn+dpIPllK+aGfLv0ryXyR5SZLvT/LeUspX7nuLP5jkXyf58iQ/uG9tM8nLk/yNJD9SSil9Sjhq799L8v/s1PXOJP/tET/KNyT5x7XW/3D8T93XVyR5WZJXJnl7kp9M8m37ns8n+a1a66+UUlpJfjbJu3Ze8xeTfKCUcvk+Ph8AGHPCIwDgIvpzSf52rfWXa63bO/OInkvyhiSptb6/1npj5yTPE0l+LQfbwG7UWv/XWuvtWmtnZ+1Ttda/U2vdTvITSb4yye/q8/k995ZSXpHkDyT5a7XW52ut/zzJB4/4Ob4syWfu6U/gC15I8mit9bmdn+XvJfmWUspDO8//5M5aknxHkp+rtf7czp/NLyS5nuS/us8aAIAxJjwCAC6iVyb53p3Wq61SylaSr05yJUlKKX9qX0vbVpLfmzunhHb9Ro/3/M3dL2qtt3a+/OI+n99v75Ukn9u31u+zdv273Ame7sfNWut/3FfPv0zyiSRv2QmQviVfCI9emeRPHPpz+8/PoAYAYIwZqggAXES/keQHa60/ePhBKeWVSf5Okq9P8ku11u1SytNJ9reg1QHV9ZkkLyulPLQvQPrqI/b/kyTvKqW8uNb6+T57biV5aN/3X5Hk0/u+7/Wz7LauPZDk4zuBUnLnz+3v1lr/3DE/BwDAHiePAIDzrlFKeXDfr0u5Ew79D6WUP1jueHEp5Y+WUr4kyYtzJ1C5mSSllO/KnZNHA1dr/VTutIG9s5TyolLK1yZ5yxEv+bu5E+h8oJTymlLKA6WULyul/JVSym4r2dNJ/mQpZaqU8uYkf/gEpfz9JN+U5M/nC6eOkuS9uXMiaX7n/R7cGbr9Vaf8UQGACSI8AgDOu59L0tn365211uu5M/fobyV5Nsm/TPKnk6TW+vEkP5Tkl5L82yRXk3x4iPV+e5KvzZ2WtHcleSJ35jHdpdb6XO4Mzf5kkl9I8u9zZ9j2y5P88s62786dAGpr571Xjyug1vqZ3Pn5/9DO5++u/0aSP5bkr+ROuPYbSRbj/yYEAI5Qah3UqW0AAEopTyT5ZK310VHXAgBwL/x/mQAAzlAp5Q+UUn73Tgvam3PnpM+xp4UAAM4rA7MBAM7WVyRZSfJluTPY+s/XWtdHWxIAwL3TtgYAAABAX9rWAAAAAOjrQrStvfzlL6+vetWrRl0GAAAAwNh46qmnfqvWevm4fRciPHrVq16V69evj7oMAAAAgLFRSvnUSfZpWwMAAACgL+ERAAAAAH0JjwAAAADoS3gEAAAAQF/CIwAAAAD6Eh4BAAAA0JfwCAAAAIC+hEcAAAAA9CU8AgAAAKAv4REAAAAAfQ0sPCql/Ggp5bOllF/t8ewvllJqKeXlg/p8AAAAAO7fIE8e/XiSNx9eLKV8dZJvTPLMAD8bAAAAgDMwsPCo1vqLST7X49G7k/ylJHVQnw0AAADA2RjqzKNSyrckaddaP3qCvW8vpVwvpVy/efPmEKoDAAAA4LChhUellIeS/NUkf+0k+2ut76m1ztVa5y5fvjzY4gAAAADoaZgnj353klcn+Wgp5d8k+aokv1JK+Yoh1gAAAADAKVwa1gfVWjeSfPnu9zsB0lyt9beGVQMAAAAApzOwk0ellJ9M8ktJZkopny6l/NlBfRYAAAAAgzGwk0e11m875vmrBvXZAAAAAJyNod62BgAAAMDFMrSZR5Nudb2dd37wY9nqdPfWXvpQI4++5bVZmG2NsDIAAACA/kqtddQ1HGtubq5ev3591GXcs9X1dhbf/9F0Xzj+z1qgBAAAAAxDKeWpWuvccfu0rQ3B8trmiYKjJHn2Vjff88TTmf2Bn8/qenvAlQEAAAAcTXg0BDe2Oqd+zW6I9Nq/9o+FSAAAAMDICI+G4Mp0855f+/nnt7P40x8VIAEAAAAjITwagsX5mTQeKPf8+u52zTs/+LEzrAgAAADgZIRHQ7Aw28ryn/iaTDcb9/weW52uOUgAAADA0LltbQRW19tZXttMe6uTkuQ0/wmUJN/+hlfkXQtXB1QdAAAAMAlOetvapWEUw0ELs60szLbuWv++1Y289yPPHPnamuR9H3kmc698Wc/3AAAAADhL2tbOkXctXM0Pv+11KceMR6qJGUgAAADAUAiPzpmF2Vbe/a2vS7MxdeS+rU7X/CMAAABg4IRH59DCbCuPXbt67IBtp48AAACAQRMenVMLs608/eg35Tve8Iq+e5w+AgAAAAZNeHTOvWvhal76UP8TSN/7Ux8VIAEAAAADIzy6AB59y2v7PtuuNUsrGwIkAAAAYCCERxfAwmzryNNHne62+UcAAADAQAiPLohH3/LaI29gM/8IAAAAGATh0QWxewPbVCl99yyvbQ6xIgAAAGASXBp1AZzcwmwrSfI9Tzzd83l7qzPMcgAAAIAJ4OTRBXPU/KOSaF0DAAAAzpTw6AJ69C2vTa/mtRqtawAAAMDZEh5dQAuzrdQ+z9pbHaePAAAAgDMjPLqgWtPNvs+WVjYESAAAAMCZEB5dUIvzM2k2pno+63S3ta8BAAAAZ8JtaxeUm9cAAACAYXDy6AJbmG31bV9z8xoAAABwFoRHF9zi/Iyb1wAAAICBER5dcMfdvAYAAABwP4RHY0DrGgAAADAowqMxoHUNAAAAGBTh0Rg4qnXthtY1AAAA4D4Ij8ZEv9a1K33WAQAAAE5CeDQmFudn0mxMHVgrSd74msujKQgAAAAYC8KjMbEw28pbX986MPuoJvnAU21DswEAAIB7JjwaIx/65M27Zh91utuGZgMAAAD3THg0RvoNxzY0GwAAALhXwqMx0m849gOlaF0DAAAA7onwaIz0GpqdJNu1ZmllQ4AEAAAAnJrwaIwszLby2LWrmSrlrmdmHwEAAAD3Qng0ZhZmW3mhHh6bfYfZRwAAAMBpCY/GUL/ZR/3WAQAAAPoRHo2hXrOPSpI3vubyaAoCAAAALizh0RhamG3lra9vZf/ko5rkA0+1Dc0GAAAATkV4NKY+9MmbOTz5yNBsAAAA4LSER2Oq33BsQ7MBAACA0xAejSlDswEAAICzIDwaU72GZjcbU1mcnxlRRQAAAMBFJDwaUwuzrTx27Wqmm429tQcb/uMGAAAATkeaMOaeu/3C3tfP3upmaWXDjWsAAADAiQmPxtjy2mY63e0Da25cAwAAAE5DeDTG3LgGAAAA3C/h0Rhz4xoAAABwv4RHY6zXjWslyRtfc3k0BQEAAAAXjvBojC3MtvLW17dS9q3VJB94qm1oNgAAAHAiwqMx96FP3kw9tGZoNgAAAHBSwqMxZ2g2AAAAcD+ER2PO0GwAAADgfgiPxlyvodnNxlQW52dGVBEAAABwkVwadQEM1sJsK0myvLaZG1udXJluZnF+Zm8dAAAA4Cil1sPjlM+fubm5ev369VGXceGtrreFSAAAAECSpJTyVK117rh9Th5NiNX1dpZWNtLpbidJ2ludLK1sJIkACQAAAOjLzKMJsby2uRcc7ep0t7O8tjmiigAAAICLYGDhUSnlR0spny2l/Oq+teVSyidLKf+ilPIPSinTg/p8Drqx1TnVOgAAAEAy2JNHP57kzYfWfiHJ7621/r4k/1+SpQF+PvtcmW6eah0AAAAgGWB4VGv9xSSfO7T287XW2zvffiTJVw3q8zlocX4mzcbUgbVmYyqL8zMjqggAAAC4CEY58+jPJPlH/R6WUt5eSrleSrl+8+bNIZY1nhZmW3ns2tVMNxt7aw82jLwCAAAAjjaS9KCU8leT3E7yvn57aq3vqbXO1VrnLl++PLzixtxzt1/Y+/rZW90srWxkdb09wooAAACA82zo4VEp5TuTfHOSb6+11mF//iRz4xoAAABwWpeG+WGllDcn+ctJ/nCt9dYwPxs3rgEAAACnN7CTR6WUn0zyS0lmSimfLqX82SR/K8mXJPmFUsrTpZT/Y1Cfz93cuAYAAACc1sBOHtVav63H8o8M6vM43uL8TJZWNg60rrlxDQAAADjKUNvWGK2F2VaSO7OPbmx1cmW6mcX5mb11AAAAgMOERxPmcIC0OyxbgAQAAAD0IjyaMKvr7QOta+2tTpZWNpIIkAAAAIC7DWxgNufT8trmgZlHSdLpbu+dQAIAAADYT3g0YW5sdU61DgAAAEw24dGEuTLdPNU6AAAAMNmERxNmcX4mzcbUgbVmYyqL8zMjqggAAAA4zwzMnjCHb1u7Mt3M4vyMYdkAAABAT8KjCXQ4QNodli1AAgAAAA4THk2g1fV2llY29m5da291srSykUSABAAAABxk5tEEWl7b3AuOdnW623snkAAAAAB2CY8m0I2tzqnWAQAAgMklPJpAV6abp1oHAAAAJpfwaAItzs+k2Zg6sNZsTGVxfmZEFQEAAADnlYHZE+jwbWtXpptZnJ8xLBsAAAC4S6m1jrqGY83NzdXr16+PuoyxtLreFiIBAADABCqlPFVrnTtun5NHE2x1vZ2llY29m9faW50srWwkiQAJAAAASGLm0URbXtvcC452dbrbWV7bHFFFAAAAwHkjPJpgN7Y6p1oHAAAAJo/waIJdmW6eah0AAACYPMKjCbY4P5NmY+rAWrMxlcX5mRFVBAAAAJw3BmZPsN2h2G5bAwAAAPoRHk24hdmWsAgAAADoS3hEVtfbTh8BAAAAPQmPJtzqejtLKxvpdLeTJO2tTpZWNpJEgAQAAAAYmD3pltc294KjXZ3udpbXNkdUEQAAAHCeCI8m3I2tzqnWAQAAgMkiPJpwV6abp1oHAAAAJovwaMItzs+k2Zg6sNZsTGVxfmZEFQEAAADniYHZE253KLbb1gAAAIBehEfcFSDtDssWIAEAAADCI7K63s7SysberWvtrU6WVjaSCJAAAABg0pl5RJbXNveCo12d7vbeCSQAAABgcgmPyI2tzqnWAQAAgMkhPCJXppunWgcAAAAmh/CILM7PpNmYOrDWbExlcX5mRBUBAAAA54WB2Ry4ba291clUKQdmHhmaDQAAAJPLySOS3AmIdk8gbdea5Au3rq2ut0dcHQAAADAqwiP2uHUNAAAAOEx4xB63rgEAAACHCY/Y49Y1AAAA4DDhEXvcugYAAAAcJjxiz8JsK49du5rpZmNv7cGGvyIAAAAwySQD3OW52y/sff3sra4b1wAAAGCCCY84wI1rAAAAwH7CIw5w4xoAAACwn/CIA9y4BgAAAOwnPOKAXjeulSRvfM3l0RQEAAAAjJTwiAMWZlt56+tbKfvWapIPPNU2NBsAAAAmkPCIu3zokzdTD60Zmg0AAACTSXjEXQzNBgAAAHYJj7hLv+HYL2k2hlwJAAAAMGrCI+6yOD+TxgPlrvXPP3/b3CMAAACYMMIj7rIw28oXP3jprvXudjX3CAAAACaM8Iietm51e66bewQAAACTRXhET/3mHvVbBwAAAMaT8IieFudn0mxMHVhrNqayOD8zoooAAACAUbh7sA3kztyjJFle20x7q5OpUtLpbu/NPNp9DgAAAIw3J4/oa2G2tXcCabvWJEl7q5OllQ23rgEAAMCEEB5xpOW1zXS62wfW9p9AAgAAAMab8Igj9btdza1rAAAAMBmERxzJrWsAAAAw2YRHHMmtawAAADDZBhYelVJ+tJTy2VLKr+5be1kp5RdKKb+28/tLB/X5nI2F2VYeu3Y1083G3tqDDZkjAAAATIpBpgA/nuTNh9YeSfJPa63/aZJ/uvM9F8Bzt1/Y+/rZW103rgEAAMCEGFh4VGv9xSSfO7T8x5L8xM7XP5FkYVCfz9lx4xoAAABMrmH3H/2uWutnkmTn9y/vt7GU8vZSyvVSyvWbN28OrUDu1u9mtbYb1wAAAGDsndvhNbXW99Ra52qtc5cvXx51OROt381qJdG6BgAAAGNu2OHRvy2lfGWS7Pz+2SF/PvdgcX4mpcd6TbSuAQAAwJgbdnj0wSTfufP1dyb5v4b8+dyDhdlWap9n/VraAAAAgPEwsPColPKTSX4pyUwp5dOllD+b5PEk31hK+bUk37jzPRdAq0/rWr+WNgAAAGA8XBrUG9dav63Po68f1GcyOIvzM1la2Thw61qzMZXF+ZkRVgUAAAAM2sDCI8bLwmwryZ0ZRze2Orky3czi/MzeOgAAADCehEec2OEAaXdYtgAJAAAAxpfwiBNbXW8faF1rb3WytLKRRIAEAAAA42rYt61xgS2vbR6YeZQkne723gkkAAAAYPwIjzixG1udnuvtrU5W19tDrgYAAAAYBuERJ3Zlutn32dLKhgAJAAAAxpDwiBNbnJ9JszHV85n2NQAAABhPBmZzYrtDsb/niad7Pu/X1gYAAABcXE4ecSoLs620+rSvHdXWBgAAAFxMwiNOrVf7WrMxlcX5mRFVBAAAAAyK8IhTW5ht5bFrVzPdbOytPdjwVwkAAADGkX/xc8+eu/3C3tfP3uq6cQ0AAADGkPCIe7K8tplOd/vAmhvXAAAAYPwIj7gn/W5Wa7txDQAAAMaK8Ih70u9mtZJoXQMAAIAxIjzinizOz6T0WK+J1jUAAAAYI8Ij7snCbCu1z7N+LW0AAADAxSM84p61+rSu9WtpAwAAAC4e4RH3bHF+Js3G1IG1kuSNr7k8moIAAACAMyc84p4tzLby1te3Dsw+qkk+8FTb0GwAAAAYE8Ij7suHPnnzrtlHne52vvenPipAAgAAgDEgPOK+9BuOvV1rllY2BEgAAABwwQmPuC9HDcfudLezvLY5xGoAAACAsyY84r70Gpq9X7+TSQAAAMDFIDzivizMtvLYtauZKqXn86NOJgEAAADnn/CI+7Yw28oPfevX3HUCqdmYyuL8zIiqAgAAAM6C8IgzsXsCabrZ2Ft7sOGvFwAAAFx0/nXPmXru9gt7Xz97q+vGNQAAALjghEecmeW1zXS62wfW3LgGAAAAF5vwiDPT72a1thvXAAAA4MISHnFm+t2sVhKtawAAAHBBCY84M4vzMyk91muidQ0AAAAuKOERZ2ZhtpXa51m/ljYAAADgfBMecaZafVrXHihF6xoAAABcQMIjztTi/Eyajam71rdrzdLKhgAJAAAALhjhEWdqYbaVx65dzVS5e/pRp7tt9hEAAABcMMIjztzCbCsv1N7Tj8w+AgAAgItFeMRAXOkz+6jfOgAAAHA+CY8YiF6zj5qNqSzOz4yoIgAAAOBeCI8YiN3ZR9PNxt7agw1/3QAAAOCi8a95Buq52y/sff3sra4b1wAAAOCCER4xMMtrm+l0tw+suXENAAAALhbhEQPT72a1thvXAAAA4MIQHjEw/W5WK4nWNQAAALgghEcMzOL8TEqP9ZpoXQMAAIALQnjEwCzMtlL7POvX0gYAAACcL8IjBqrVp3WtX0sbAAAAcL4IjxioxfmZNBtTB9ZKkje+5vJoCgIAAABORXjEQC3MtvLW17cOzD6qSd77kWcy+wM/b3A2AAAAnHPCIwbuQ5+82XP20bO3ulla2RAgAQAAwDkmPGLgjhqO3eluu3kNAAAAzjHhEQN33HBsN68BAADA+SU8YuB6Dc3e7yXNxhCrAQAAAE5DeMTALcy28ti1q5nuExJ9/vnb5h4BAADAOSU8YigWZlt5+tFvyksfujtA6m5Xc48AAADgnBIeMVRbt7o91809AgAAgPNJeMRQ9RuefdxQbQAAAGA0hEcMVa/h2c3GVBbnZ0ZUEQAAAHAU4RFD1Wt49oMNfw0BAADgvPKvdkbiudsv7H397K1ullY23LgGAAAA55DwiKFbXttMp7t9YK3T3XbjGgAAAJxDwiOGrt/Nam5cAwAAgPNHeMTQ9btZ7SX75iABAAAA58NIwqNSyjtKKR8rpfxqKeUnSykPjqIORmNxfiaNB8pd61udbl71yM/m4cefNP8IAAAAzomhh0ellFaSv5Bkrtb6e5NMJflvhl0Ho7Mw28oXP3ip7/P2VscAbQAAADgnRtW2dilJs5RyKclDSW6MqA5GZOtW98jnBmgDAADA+TD08KjW2k7yN5M8k+QzSX671vrzh/eVUt5eSrleSrl+8+bNYZfJgPWbe7SfAdoAAAAweqNoW3tpkj+W5NVJriR5cSnlOw7vq7W+p9Y6V2udu3z58rDLZMAW52fSbEwdueckARMAAAAwWKNoW/uGJL9ea71Za+0mWUnyh0ZQByO0MNvKY9euZrrPDWuNqZLF+ZkhVwUAAAAcNorw6JkkbyilPFRKKUm+PsknRlAHI7Yw28qLv6j34OwXv+hSFmZbQ64IAAAAOGwUM49+OclPJ/mVJBs7Nbxn2HVwPvSba/TbnaMHagMAAADD0f++9AGqtT6a5NFRfDbny5XpZto9AiTzjgAAAOB8GEXbGuzpNzj71vO3s7reHkFFAAAAwH7CI0aq3+DsZ291s7SyIUACAACAERMeMXL9Bmd3uttZXtscQUUAAADALuER50K/wdntrU4efvxJJ5AAAABgRIRHnAtHDchub3W0sAEAAMCICI84F/oNzt6lhQ0AAABGQ3jEubA7OHuqlL57+rW2AQAAAIMjPOLcWJht5YVa+z4/qrUNAAAAGAzhEedKv4Co5E5rGwAAADBcwiPOlV6zj0qSb3/DK7Iw2xpNUQAAADDBLo26ANhvNyBaXtvMja1Orkw3szg/IzgCAACAESn1iBkz58Xc3Fy9fv36qMtgyFbX20IkAAAAGJBSylO11rnj9jl5xLm0ut7O0spGOt3tJEl7q5OllY0kESABAADAEJl5xLm0vLa5Fxzt6nS3s7y2OaKKAAAAYDIJjziXbmx1eq63tzp5+PEns7reHnJFAAAAMJmER5xLV6abfZ/ttrAJkAAAAGDwhEecS4vzM2k2pvo+18IGAAAAwyE84lxamG3lra9vpRyxp19rGwAAAHB2hEecWx/65M3UI54f1doGAAAAnA3hEefWUSeLmo2pLM7PDLEaAAAAmEzCI86tfieLpkrJY9euZmG2NeSKAAAAYPIIjzi3eg3Nbjam8kPf+jWCIwAAABgS4RHn1sJsK49du5rWdDMlyXSzkQcbD+QdTzydhx9/Mqvr7VGXCAAAAGNPeMS5tjDbyocfeVPe/bbX5bnbL+TZW93UJO2tTpZWNgRIAAAAMGDCIy6E5bXNdLrbB9Y63e0sr22OqCIAAACYDMIjLoR+N68ddSMbAAAAcP+ER1wI/W5e67cOAAAAnI0ThUellN9dSvmina+/rpTyF0op04MtDb6g181rSXLr+dvmHgEAAMAAnfTk0QeSbJdSfk+SH0ny6iR/b2BVwSG7N69NNxsH1p+91TU4GwAAAAbopOHRC7XW20n+eJIfrrW+I8lXDq4suNvCbCul3L1ucDYAAAAMzknDo24p5duSfGeSf7iz1jhiP5y51fV2nr3V7fnM4GwAAAAYjJOGR9+V5GuT/GCt9ddLKa9O8t7BlQV3O+p0kcHZAAAAMBiXTrKp1vrxJH8hSUopL03yJbXWxwdZGBx21OmixfmZIVYCAAAAk+Okt639s1LKl5ZSXpbko0l+rJTyPw+2NDjoqNNFy2ubhmYDAADAAJy0be0ltdZ/n+Rakh+rtb4+yTcMriy42+L8TJqNqZ7P2lsdt64BAADAAJw0PLpUSvnKJN+aLwzMhqFamG3lsWtX0+pzAsmtawAAAHD2Thoe/UCStST/qtb6/5ZS/pMkvza4sqC3hdlWPvzIm1L6PHfrGgAAAJytkw7Mfn+S9+/7/l8neeugioLjXJlupt0jKHLrGgAAAJytkw7M/qpSyj8opXy2lPJvSykfKKV81aCLg356zT9qNqbcugYAAABn7KRtaz+W5INJriRpJfmZnTUYicPzj6ZK2Zt5ZGg2AAAAnJ2ThkeXa60/Vmu9vfPrx5NcHmBdcKyF2Vbe+JrLKUm2a03i1jUAAAA4aycNj36rlPIdpZSpnV/fkeTfDbIwOM7qejvv+8gzqYfW3boGAAAAZ+ek4dGfSfKtSX4zyWeS/NdJvmtQRcFJLK9t3hUc7XLrGgAAAJyNE4VHtdZnaq3fUmu9XGv98lrrQpJrA64NjnRUQPSSZmOIlQAAAMD4OunJo17+pzOrAu7BlZ1h2b18/vnb5h4BAADAGbif8KicWRVwDxbnZ9JsTPV81t2u5h4BAADAGbh0H6/tN24GhmJhtpUk+Z4nnu753NwjAAAAuH9HnjwqpfxOKeXf9/j1O0muDKlG6GthtpVWn/a1o9raAAAAgJM5MjyqtX5JrfVLe/z6klrr/ZxagjPTq32t8UDJredv59WP/GwefvxJ848AAADgHgmAuPB229cgo+ODAAAgAElEQVSW1zZzY6uTlzQb+fzzt/PsrW6SpL3VydLKxoG9AAAAwMncz8BsODcWZlv58CNvyq8//kfz4i+6lO72wZFcne62AdoAAABwD4RHjJ1+g7IN0AYAAIDTEx4xdvoNyjZAGwAAAE5PeMTY6TVAu9mYyuL8zIgqAgAAgIvLwGzGzuEB2lemm1mcnzEsGwAAAO6B8IixsrrePhAavfttrxMaAQAAwH0QHjE2VtfbWVrZSKe7nSRpb3WytLKRJAIkAAAAuEdmHjE2ltc294KjXZ3udpbXNkdUEQAAAFx8wiPGxo2tzqnWAQAAgOMJjxgbV6abPddf0mwMuRIAAAAYH2YeMTYW52ey+P6PpvtCPbD++edvZ3W9ncQNbAAAAHBawiPGxsJsK9//Mx/Ls7e6B9a72zXv/ODH8tztFwzTBgAAgFPStsZY2ToUHO2td7qGaQMAAMA9GEl4VEqZLqX8dCnlk6WUT5RSvnYUdTB++s096scwbQAAADjaqE4e/S9J/nGt9TVJvibJJ0ZUB2NmcX4mzcbUgbVmYyovfaj30OzThk0AAAAwaYYeHpVSvjTJf5nkR5Kk1vp8rXVr2HUwnhZmW3ns2tW0ppspSVrTzbz19a3UevfeZmMqi/MzQ68RAAAALpJSe/2repAfWMrrkrwnycdz59TRU0m+u9b6+UP73p7k7Unyile84vWf+tSnhlon4+H7Vjfyvo88k8N/y1/6UCOPvuW1hmUDAAAwsUopT9Va547bN4q2tUtJfn+S/73WOpvk80keObyp1vqeWutcrXXu8uXLw66RMbC63u4ZHCXJQy+6JDgCAACAExhFePTpJJ+utf7yzvc/nTthEpyp5bXNnsFRYlA2AAAAnNTQw6Na628m+Y1Syu6wma/PnRY2OFNHBUQGZQMAAMDJXBrR5/6PSd5XSnlRkn+d5LtGVAdj7Mp0M+0eAVJJDMoGAACAExpJeFRrfTrJsQOZ4H4szs9kaWUjne723lpJ8u1veEWS5OHHn8yNrU6uTDezOD9jBhIAAAD0MKqTRzBwu2HQ8trmgZAoyYFQqb3VydLKxoHXAAAAAHeUWvuNFD4/5ubm6vXr10ddBhfY6np7L0RKSXr9tZ8qJT/0rV8jQAIAAGAilFKeqrUe2xnm5BFjb3W9fbB9rU9eul2rE0gAAABwyNBvW4NhW17bPDD36Cid7naW1zYHXBEAAABcHMIjxt6NHjeuneV+AAAAGGfCI8belenmQPcDAADAOBMeMfYW52fSbEydaG+zMbV3IxsAAABgYDYTYHf49e5tay9pNlJKsnWre+DrK9PNLM7PGJYNAAAA+wiPmAgLsy2hEAAAANwD4RETa3W93fM0khNIAAAA8AXCIybS6no7Sysb6XS3kyRbne7es/ZWJ0srG0kiQAIAAGDiGZjNRFpe29wLjnrpdLezvLY5xIoAAADgfBIeMZFubHWO3dM+wR4AAAAYd8IjJtKV6eaxe0rutLcBAADAJBMeMZEW52fSbEwduacmWtcAAACYeAZmM5F2B2Hv3rZW++w7SXsbAAAAjDPhERNrYba1FyI9/PiTPWccnaS9DQAAAMaZtjVI7za2ZmMqi/MzI6oIAAAAzgcnjyB3t7FdmW5mcX5mbx0AAAAmlfAIduxvYwMAAADuEB7BPqvrbaePAAAAYJ9Sa797ps6Pubm5ev369VGXwZhbXW9naWUjne723lrjgZIvfvBStm51hUkAAACMlVLKU7XWueP2OXkEO5bXNg8ER0nSfaHm2VvdJEl7q5OllY0kESABAAAwMdy2BjtubHWO3dPpbmd5bXMI1QAAAMD5IDyCHVemmyfa197q5OHHn8zqenvAFQEAAMDoCY9gx+L8zIn37rawCZAAAAAYd8Ij2LEw28pLH2qceL8WNgAAACaB8Aj2efQtr02zMXXi/SeZkwQAAAAXmdvWYJ/dW9SW1zZzY6uTB0rJdq199590ThIAAABcVMIjOGRhtrUXIq2ut7O0spFOd/uufc3G1KnmJAEAAMBFJDyCI+w/idTe6mRq5yRSa7qZxfmZvecAAAAwroRHcIz9J5EAAABg0giPoI/V9fbe7KMrThoBAAAwoYRH0MPhWUftrU6WVjaSRIAEAADARHlg1AXAebS8tnnXkOxOdzvLa5sjqggAAABGQ3gEPdzY6pxqHQAAAMaVtjXo4cp0M+0eQdFLmo08/PiT5iABAAAwMZw8gh4W52fSbEwdWGs8UPL552+nvdVJzRfmIK2ut0dTJAAAAAyB8Ah6WJht5bFrV9OabqYkaU0388UPXkp3ux7YZw4SAAAA407bGvSxMNs60JL26kd+tue+Xu1tAAAAMC6cPIITujLd7LleEq1rAAAAjC3hEZzQ4vxMSo/1mmhdAwAAYGwJj+CEFmZbqX2e3dC6BgAAwJgSHsEptPq0rvVraQMAAICLTngEp7A4P5NmY+rAWrMxlcX5mRFVBAAAAIMlPIJTWJht5bFrVzPdbOytPdjwXyMAAADG16VRFwAX0XO3X9j7+tlb3SytbCS5Ey6trrezvLaZG1udXJluZnF+JguzrVGVCgAAAPel1NpvBPD5MTc3V69fvz7qMiBJ8vDjT6bdY0D2VCnZrjUlOTBYu9mYymPXrgqQAAAAOFdKKU/VWueO26ffBk6p381q2ztB7OE4ttPdzvLa5oCrAgAAgMEQHsEp3cvNav0CJwAAADjvhEdwSr1uXDvOvQROAAAAcB4Ij+CUet24dpRmYyqL8zMDrgoAAAAGQ3gE92BhtpUXf1H/ywrLzu+t6aZh2QAAAFxo/f/1CxzpqDlG737b6wRGAAAAjAUnj+Ae9ZtjNN1sCI4AAAAYG8IjuEeL8zNpPFDuWt/qdDP7Az+f1fX2CKoCAACAsyU8gnu0MNvKFz/Yu/Pz2VvdLK1sCJAAAAC48IRHcB+2bnX7Put0t7O8tjnEagAAAODsCY/gPvSbe7SrvdXJqx/52Tz8+JNOIQEAAHAhCY/gPizOz6TZmDpyT82dEEkbGwAAABeR8Ajuw8JsK49du5rpZuPYvdrYAAAAuIiER3CfFmZbefrRb8oPv+11aR3TxnZjqzOkqgAAAOBsCI/gjCzMtvLhR96UcsSe42YkAQAAwHkzsvColDJVSlkvpfzDUdUAg9AvICq5MyMJAAAALpJRnjz67iSfGOHnw0D0G6L90Ium8o4nnnbzGgAAABfKSMKjUspXJfmjSf7PUXw+DNLuEO3WdDMlyXSzkcZUyeef3967ee17nng6sz/w80IkAAAAzr1RnTz64SR/KckL/TaUUt5eSrleSrl+8+bN4VUGZ2B3/tG73/a6/M5/vJ3udr1rz7O3ulla2RAgAQAAcK4NPTwqpXxzks/WWp86al+t9T211rla69zly5eHVB2cndX1dpZWNrJd7w6OdnW621le2xxiVQAAAHA6ozh59HCSbyml/Jskfz/Jm0op7x1BHTBQy2ub6XS3j913Y6szhGoAAADg3lwa9gfWWpeSLCVJKeXrkvzFWut3DLsOGLSThkL9bmdL7pxeWl7bzI2tTq5MN7M4P5OF2dZZlQgAAADHGuVtazDWjgqFdjUbU1mcn+n5bLftrb3V2Ru0bUYSAAAAwzbS8KjW+s9qrd88yhpgUBbnZ9JsTPV9XpK89fWtvieJerW9mZEEAADAsA29bQ0mxW4otLy2mXaPFraa5L0feSbv/cgzeelDjTz6ltceCJL6tb2ZkQQAAMAwaVuDAVqYbeXDj7wp5Zh9z97q5nueeDrft7qxt9av7e0k7XAAAABwVoRHMAQnDXze95Fn9mYa9Wp7O2pGEgAAAAyC8AiG4Lj5R7tqknd+8GNJ7pxaeuza1bSmmylJWtPNPHbtqtvWAAAAGCozj2AIjpt/tN9Wp5vV9XYWZlt7vwAAAGBUSq111DUca25url6/fn3UZcCZWF1vZ/H9H033hf7/3ZsqJS/UmivTzSzOzwiQAAAAOHOllKdqrXPH7XPyCIZsNwhaWvkX6XRf6LlneyfUbW91srSyceB1AAAAMExmHsEILMy28om//kfy0ocax+7tdLezvLY5hKoAAADgbsIjGKFH3/LaEw3SPm5OEgAAAAyK8AhG6PCNalOl9NxXcmdWEgAAAAybmUcwYvtvVFtdb+cdTzydw6O0a+7c1GbuEQAAAMPm5BGcIwuzrbuCo103tK4BAAAwAsIjOGda082e61f6rAMAAMAgCY/gnFmcn7lriHazMZXF+ZkRVQQAAMAkM/MIzpHV9XaW1zbT6W5nqpRs15rWdDOL8zOnmne0+z43tjq5cg+vBwAAgF3CIzgnVtfbWVrZSKe7nSTZrnXvxNFpg6P979Pe6mRpZSNJBEgAAACcmrY1OCe+/2c+thf47Op0t7O8tnmq99k9uXS/7wMAAACJk0dwLqyut/PsrW7PZ+2tTh5+/MkDLWhJ+ral9buVzW1tAAAA3AvhEZwDR50KKrkTIGXn98X3fzQpSXe77q3tb0u7Mt3c27+f29oAAAC4F9rW4Bw46lRQPfR994W6Fxzt2t+W5rY2AAAAzpLwCM6BszgVtBtALcy28ti1q2lNN1OStKabeezaVcOyAQAAuCfa1uAcWJyfOXBDWnLntNCDjQf6zkI6bH8AtTDbEhYBAABwJoRHcA7sBj2Hh2AnuStUajxQDsw8SrSlAQAAMDjCIzgnjjot1CtU6nfbGgAAAJylUuvhcbznz9zcXL1+/fqoywAAAAAYG6WUp2qtc8ftc/IILpDV9XbfE0dHPQMAAIB7JTyCC2J1vX1g/lF7q5N3PPF0rn/qc5l75cvuera0spEkAiQAAADuywOjLgA43up6O9/7Ux89MDg7SWqS933kmXz/z3zsrmed7naW1zaHWCUAAADjSHgE59zuiaPtPvPJapJnb3V7Prux1RlgZQAAAEwC4RGcc8trm3edKjqpK9PNM64GAACASSM8gnPuXk8PNaZKFudnzrgaAAAAJo3wCM65ez099OIXXTIsGwAAgPsmPIJzbnF+Js3G1Klf99ud3nOQAAAA4DSER3DOLcy28ti1q2lNN1OStE54Esm8IwAAAM7CpVEXABxvYbZ1oAXt4cefTPuYWUj3O+9odb2d5bXN3Njq5Mp0M4vzM9rgAAAAJpDwCC6gxfmZLK1s9L2FbbrZyMJs68gA6Lhn+9+/vdXJ0spGkgiQAAAAJozwCC6g3QDnnR/8WLYOzTZqNqbyzm957ZEBUJIjw6Hltc27gqlOdzvLa5vCIwAAgAkjPIILareVrd8Joocff7JvALT7da9nC7Ot3OjTEtdvHQAAgPElPIIL7vA8pF39ZiIdFQDtPrsy3ez5ekO4AQAAJo/b1mAMra63U/o8uzLd7BsC7a4vzs+k2Zg68KzZmLrvIdwAAABcPE4ewRhaXttM7bFe8oVb2A4P3N4fDu2eZHLbGgAAAMIjGEP9WtN2A6WThEP92uEAAACYLMIjGEP9ZhYlOXCrmnAIAACA45h5BGOo18yiXftvXAMAAIDjOHkEY2R1vb3XivaSZuPATKP9jrpx7fD7mHcEAAAw2YRHMCZW19sHhmBvdbopSc/B2f1uW+v1Pu2tzoFWNwAAACaLtjUYE8trm3edNKq5c8PafvtvVTvp+2h1AwAAmFxOHsGYOOqGtdZ088gWtP1tar1OKh31/v3eR7sbAADAeHDyCMZEv1a01nQzH37kTXn3216XJHnHE0/n4cefzOp6O8kX2tTaRwRHR73/rsPvs9vutvs5AAAAXEzCIxgTvW5Y221ROyrY6dWmdlhjqhzZ6pZodwMAABhX2tZgTOy2h/VqG3v48Sd7Bjvv/ODHstXpHvveL37RpWPbz/q1tZ2k3Q0AAIDzS3gEY2RhttUz5OkX4JwkOEqS3z7BvivTzbR7fM5x7W4AAACcb9rWYALcb4Bzktcf1TYHAADAxSU8ggnQK9g5qf0B0Op6Ow8//mRe/cjPHhi6ndw59fTYtatpTTdTcmdQ92PXrrptDQAA4ILTtgYTYGG2leuf+lze95FnjrxR7bCS5K2vv9MKtzt0e3d20u7Q7d333/193MOi3SHjh+dKAQAAjCvhEUyID33y5qmCoySpO69L+t+m9r0/9dEkmYgA5SQBGgAAwLjRtgYT4l5vPdt9Xb/Xb9eapZWNAy1s46pfgLa8tjmiigAAAAZPeAQT4l6HZu++7qjXT0qA0i9Au9dgDgAA4CIQHsGEWJyfSTnla/YPyz5u6HZ7qzP2p4/6BWj3e5sdAADAeSY8ggmxMNvKt7/hFScOkHrdlvZFl47+n4xxb1/rFaDtD9gAAADGkYHZMEHetXA1c6982d5tYS9pNvL552+nu/2FUdrNxtRdodHhQdH9jPsA7d2fyW1rAADAJCm1nvb+peGbm5ur169fH3UZMJZOcvX8w48/mfYp5vr0CqAAAAA4X0opT9Va547b5+QRTLiF2daxIc9pB0LvDtAWHgEAAFx8Q595VEr56lLKh0opnyilfKyU8t3DrgE4nemHGqd+jRvIAAAAxsMoTh7dTvK9tdZfKaV8SZKnSim/UGv9+AhqAY7xfasbefZW99Svm4QbyE7S8gcAAHDRDT08qrV+Jslndr7+nVLKJ5K0kgiP4JxZXW/nfR955tSv272BbJzDlcNDxNtbnSytbCQZz2HhAADA5Bp629p+pZRXJZlN8ss9nr29lHK9lHL95s2bwy4NyJ1bxe5lpP6DjQdy/VOfy9LKRtpbndR8IVxZXW+fdZkjsby2edftc7uzngDg/2/v/oPjOu96j3++Wm3ilcP1Jqnp1Ju6daE4FJzYiaa4uJeJ3RIH3EtUN5CG9NLLAJ25UwZcikHhdiZpb7kWYyDl18Bk2nKBG3KTNKkIdSGU2kwZD24rR3bdkKS0zQ+yzm1c4k0g2sZr6Xv/2HPk1eo8q11ptT/Ovl8zHmnPnrP7aB95ZX/0fb4PAABp0rWG2WZ2iaQHJO1z95fq73f3uyTdJVV3W+vw8ABo+X2Lzs5UdPexZxYFT7XhSr9XJIVeG3o9AQAAAEibroRHZpZVNTi6290f7MYYACxtQz6nYiAMyWZMldlwrhu6J65Aavdyr04vkQu9NoPQ6wkAAADAYOnGbmsm6ROSHnP33+308wNo3v7dm5XLZhYcM0nv2b5RB2+6WoV8TtbiY2bM2r7cK+4/1MklckmvTdzrCQAAAADSxNw7uyLMzN4q6R8lnZI0Fx3+DXf/bOia0dFRn5qa6sTwANRppqJnx8ThYIVSLVO4Iim+fzlVQ6HnL+RzOjq+q+nHaVWaG4IDAAAASD8zO+7uo0ue1+nwaDkIj4DeVr/z2ErFIVOhyUBm0/ihxFDKJD05sactYwIAAACAtGk2POrqbmsA0mFsW0EH9m5p2+PFQVCzy89CfYboPwQAAAAAK0d4BKAtxrYVVFiFsKZcmdUH7zvZMECi/xAAAAAArB7CIwBtkxTitMOse8MKpLjyKW7gXcjndGDvFvoPAQAAAEAbDHd7AADSIw5r7njoUZXKlbY+drwjWygQGttWICwCAAAAgFVA5RGAthrbVtCJ26/Xx27e2vZlbKeb2NENAAAAANBeVB4BWBW1lUDxlvbFFYY/G/K5+cc6XSprQ5O7sQEAAAAAls/ckza47i2jo6M+NTXV7WEAaIPa8GddLquXz51XZfbC+1Aum9G7ri3ogeNFlSuz88dN1V3Y4o/1xwstBkmEUAAAAAAGnZkdd/fRJc8jPALQTbVVSRkzzbqrkM9p55XrdeTxMyqWyosCo5BcNtNUo+zJ6aJue/DUgnCq2WsBAAAAIC2aDY/oeQSgq8a2FeZ3aZuNwuxiqawHjhe1f/dmFfK5poIj6UJT7aUcfPiJBcFRK9f2msnponZMHNam8UPaMXE4uCMdAAAAACwXPY8AdF2jMKfVJtnNnB86p98actdXUBVLZd324ClJooIKAAAAQNtQeQSg60KhTbFU1pBZS4+1oYkd3kLnNHNtL0lTBRUAAACA3kXlEYCuifsdNVqWNttCX7ZcNqP9uzcnPkdtY+z9uzcn9jyqv7bXpaWCCgAAAEBvo/IIQFfES66KKwg6amuSLh3JLmp4XfscroXLug7s3aJCPidTdae2A3u3SFJf9Q9KSwUVAAAAgN5G5RGArkhactWq2pqk71TmmnqOcmVWdzz0qE7cfn1i0NRP/YPSUkEFAAAAoLdReQSgK1aytCqT0AcpqddP6DlK5cqiqqJ+7B80tq2QWEHVq2EXAAAAgP5E5RGArtiQzyUuWcuYBfscZYdMl6wZ1tmZSuL99WFR6DmkalhUG7L0a/+gsW0FwiIAAAAAq4rKIwBdsX/3ZuWymQXHctmMbvmh1y46Lkkj2SHJFAyOJGnIbEFFUaPlW0lBUxL6BwEAAAAYdIRHALoitOTqo2NbFh3/2M1bdenai1WZbbzz2qy7bnvw1HyANLatoEtHsonn1odCoTCL/kGrb3K62FeNygEAAIBBY97CNtjdMjo66lNTU90eBoAu2jR+SM2+W5kuNNMeyQ6pMucLgqf4/kI+p/27N88v+5qcLurgw0+oWCrPL5+rPwftVd+oXKqGdvRuAgAAAFafmR1399GlzqPnEYC+0Kh/Ub3akGkm2oVtyKQ5XxgsFUtlfeDeE7p/6hk99W9lnS6VtS6XVTZj82HTSnddiwOp06WyNhBELdKoUTmvEwAAANAbWLYGoC8kLStbvOdaWH1wFHNJR7/xgoqlslzVndjql8ctd9e1uKomfuw4iGJZ1gX92qgcAAAAGCSERwD6QlKPpFu3b0xsrh2ykkW6xVK55X48japqUEWjcgAAAKD3sWwNQN9I2pZ+9HWXzS8Lk0mr2cat1SVsvVRV06vL5/bv3pzY84hG5QAAAEDvoPIIQF8b21bQ0fFduvPmrRq2VhayLU+5MqsP3neyqQqkUPXMkFlHl6718vK50K57vRBsAQAAAKhitzUAqbBj4nDTDbXbwSTdun2jPjq2JXhO0k5irVzfLqHXppDP6ej4rlV/fgAAAAC9qdnd1qg8ApAKnV4K5pLuPvZMw+qduKomk1AR1cz17dJLy+cAAAAA9B96HgFIhQ35XLC6RtKqVCW5pDseenRBL6GdV67XkcfPLOgtNBeo8Ey6vlEvouX2LQq9NjSlBgAAANAMlq0BSIWkJWK5bEYH9laXhdXfZ1rZ7mvNymUzWpMd0tmZSlPnZ4dMl6wZVmmmsiAgavT1LRUgreRaAAAAAOnV7LI1Ko8ApEIcgjSqzKmvEHrgeDGxH5G0MMRZl8uqVG4u/KlXrszqO4HnSFKZ8/mgqXZ3t4MPP7ForOXKrA4+/MSiACipQunA3i09udsaAAAAgN5H5RGAgVUbsqzLZWWmRRU/sQ9NntLdx57pSLVSvUI+p9PRTmlJnprYM/95GquMlrtcDwAAAEBjzVYeER4BQJPqQ4yZc+ebXo62EqZw3yKTdOfNW+eXtn3wvpOaTXhfT9pZrR9CmX4Iw/rhdQQAAACSsGwNAFYoKRSoDWAmp4v6wL0nVr0aKX7upOdyVZe0SdW+TknBkVRdArdp/ND8Y8Xnx6FM7RK5dgYfKw1WWlmu1w314dZqvY4AAABAN1F5BAAJmq14ef34obY9Zy47pHJlbtHxIZPmGrxVN6pMCgk9ZlKFUr1mA6F2VA1tGj+UGM6ZpCdrlut1y46Jw8Fd/pZ6HQEAAIBuo/IIAFagUcVLfP/pUlkZs2C1TysypsTgSGocHEnV4Oh0C8FRo8cslsqanC4Gw51WKm3aUTUUCsU25HNNXb/aQq97q/MBAAAA9LKhbg8AAHpR6D//cVhSjBpYLyc4SnrjnV1m/pTLZrR/9+a2him3PXhKk9PFxPuWCtVqtSNY2b97s3LZzIJj8dfcC0Kve6+EWwAAAEA7EB4BQILQf/4zZovCk/i4ScrnsspmbMF92SHTpSNZmarLmdaNZNs2zjXZ6tt4UsiyXKEwSGocqtVrR7Aytq2gA3u3qJDPzb9+vdQsu9fDLQAAAKAdCI8AIEEoFAhVGs2568mJPVp78bAqdWVElTnXyEXDenJij46O71JphTu01UZTZ2cq2nfvCf2PT1eXkmXMgte1olgqa8fE4UUVSKHgx6RF57YrWBnbVtDR8V3zr1+vBEdS74dbAAAAQDvQ8wgAEsT/+a9vDH3w4ScaVtk0s1Sr1ebW9ZLiq5fPVauhZt2Vy2a0JjuksysMqYqlsj5w7wntu/eECtHXv9Sub7WhSeg1TFuwMratkLqvCQAAAKhFeAQAAaFQIGkHsbiappkGz/t3b9b++0+qslQn7GWqjs1lSg6aWhFfH/d6OrB3S/Axk4IzghUAAACg/xEeAUALlqqm2b97c8NwqfYx7njoUZXK1eqgkeyQLs5mVJqpaEM+p51XrtcDx4uJ/ZWaUb9zWzuCpHJlVvvuPRHcYW7ITK8fPzR/fyGllUYAAADAoDFvwxbTq210dNSnpqa6PQwAaMrkdLEtS7Ump4vad++Jto0rFPqsplw2owN7t0hK//I1AAAAoN+Y2XF3H13yPMIjAOhdOyYOr6g/Ur1cNrPsaqZ6GTPNuWtoiVAqn8vqlfNzC543roRaTnVSu8I5AAAAYNA1Gx6xbA0AelhoGdy7ri3oyONndLpU1prs0KJlakkKdU2/V7qULd5hbtP4oYbnxUvzatX3Upp6+oX5rycUCE1OFxcs9au9XhIBUo8h5AMAAEgPwiMA6GHN7FjWTHVS3HeptoH1Squahsw0OV1UfiS7op3dypVZ3X3smUWBknTh65+cLi4K0WqvP/jwE5JYGtcr6ueLkA8AAKC/sWwNAPrcpvFDwQoik4JBSqPr4mu7+ROikM/p6PguSc0FXfXjjfstEVZ0Xmi+aucUAAAA3ceyNQAYEBvyuWX9Rz10ndSd5tr1iqWydkwc1v7dm3W6iQqp+tHGFUmERwuDnqEAAA/uSURBVJ0Xmq9m5hEAAAC9Z6jbAwAArMz+3ZuVy2YWHIuXqbV6XXbIlM10PziKFUvlFe04FwrHJqeL2jFxWJvGD2nHxGFNTheX/Ryr+Zj9akM+19JxAAAA9DbCIwDoc2PbCjqwd4sK+ZxM1YqjZpZrJV13yZphVWZ7IziqtdwRmbQoxIn78RRLZbku9ONZSdizGo/Zz5YbaAIAAKA30fMIADCvUR+kfC6rl8+d78lwqRmXjmR1+3/5gfnd5urlc1mtvXhYxVJ5ftleocnG2/T4WYzd1gAAAHofPY8AAC1bqn9SHAgUS+XEhtpDJs354ubVJumi4SG9cn5u9Qa/hLMzlYZL4Erlikrl6q5x8bK92l3CpPBubvT4Wax2Zz8AAAD0NyqPAADz6rdYl8K7ljWqLEm6T9Kix+4X+VxWr5yfSxx7o+biGTP9zk9dTYgCAACAntRs5RHhEQBggdVcblRbuTQo4iqsZpbAtRrIEUoBAABgJQiPAAA9bXK6qDseenR+qVi85C1k7UUZzZybDS6t6xdrL8rondcUdOTxM01VZl06ktWeq16jB44XF9xnkm7dvlEfHdvSyeFLWn6QRQAGAADQWwiPAAB9JWnJnHSh0XVtyBBqUJ1WSf2lYu9pIkBqZ2jTytLGdlwHAACA1UN4BADoO82GHKEg4l3XFhZV6AyKQk0FU+1ruPPK9YlVSz/8PZfpqX8rB1/r+sqwpXarW2pnOXakAwAA6D2ERwCAVAsFTfXHd165XkcePzMQlUpDkpa7n11tFdDkdFH77z+pSt06wmzGVJlN/neDSXpyYk/w8TeNH0qsnlrqOgAAAKwewiMAAOqElsbhgnwuq5e+U2nYfyp03Ynbr19wrDbIk0mhf3Lkc1mZSaWZypLL6uibBAAA0D6ERwAAJEiqTKpf1tWogideviUtvTxsEI1kh3RxNqOzM5WGvZoaCfVCatQXa89Vr9FnTj63aJkdwRIAAEAY4REAAE1KqmaRlNjzZ6mm0HFPoIyZZt2Vz2X1YrmyrBAFK5PNmA7edPX8UrxW5xMAACDtCI8AAOgRLJfrH3HlVLyErrZnVm0lVVL4VB9Qhc4DAADoFYRHAAD0kKSqpEKg0fe6XHZBAFGvUeNq9K6R7JAkaaYyFzw2ZNKcV/tAnTs/O388FELRAwoAAKwE4REAAH3sQ5OndPexZxYsdzNJt27fqNHXXTYfRAErEYdVzfanis8vtBBUEXABANC7CI8AAOhzzfynO9TLR9KSfZyakRkyzba69RqAJbGkEQDQC3o6PDKzGyT9nqSMpI+7+0Sj8wmPAABon1YahEsXQqg12SGVKwv3ocsOVWtWKqHt6aJzLlkzrNJMRetyWZlJpZmKZFIf/A4LAABgkbT8EqBnwyMzy0j6mqQflfSspC9LusXd/zl0DeERAAC9IVQNVd+zKQ6IGi1TWm4j8bip9dmZynz/qNrd7V76TkUUSwEAgNVWu7Nrv+rl8Ogtku5w993R7dskyd0PhK4hPAIAIJ1Wox9O0q5nUvU3hHuueo0+c/K5lpbuAQAAhBTyOR0d39XtYSxbL4dHN0m6wd1/Prr9XyX9kLv/Yt1575P0PknauHHjtU8//XRHxwkAAAZHfeVU7U5ncaVTXEm188r1iQFUfTNpSbrtwa8sWuoHAADSwyQ9ObGn28NYtmbDo+FODKaOJRxblGC5+12S7pKqlUerPSgAADC4xrYVWqp4+ujYlqYfN9RjqvbYzivX68jjZxKX/YXCqlqt7poGAADaY0M+1+0hdEQ3wqNnJb225vYVkk53YRwAAACrLhRMrUZY1azlLhcMLQlcykh2SJLmq7kAAEiDbMbmfymUdt1YtjasasPst0kqqtow+6fd/dHQNfQ8AgAAQBosN4ADAPSWQdttreOVR+5+3sx+UdLDkjKSPtkoOAIAAADSotUlkgAA9IJuLFuTu39W0me78dwAAAAAAABo3lC3BwAAAAAAAIDeRXgEAAAAAACAIMIjAAAAAAAABBEeAQAAAAAAIIjwCAAAAAAAAEGERwAAAAAAAAgiPAIAAAAAAEAQ4REAAAAAAACCCI8AAAAAAAAQRHgEAAAAAACAIMIjAAAAAAAABBEeAQAAAAAAIIjwCAAAAAAAAEGERwAAAAAAAAgiPAIAAAAAAEAQ4REAAAAAAACCCI8AAAAAAAAQRHgEAAAAAACAIMIjAAAAAAAABJm7d3sMSzKzM5Ke7vY42uRVkr7d7UGg45j3wcXcDy7mfnAx94OLuR9czP1gYt4HV5rm/nXuvn6pk/oiPEoTM5ty99FujwOdxbwPLuZ+cDH3g4u5H1zM/eBi7gcT8z64BnHuWbYGAAAAAACAIMIjAAAAAAAABBEedd5d3R4AuoJ5H1zM/eBi7gcXcz+4mPvBxdwPJuZ9cA3c3NPzCAAAAAAAAEFUHgEAAAAAACCI8AgAAAAAAABBhEcdYmY3mNkTZvZ1Mxvv9njQXmb2STN73sy+WnPsMjP7nJn9S/Tx0ui4mdnvR98LXzGza7o3cqyUmb3WzI6Y2WNm9qiZ/XJ0nPlPMTNbY2ZfMrOT0bx/ODq+ycy+GM37vWZ2UXT84uj216P7X9/N8WPlzCxjZtNm9pnoNnM/AMzsKTM7ZWYnzGwqOsb7/QAws7yZfcrMHo9+5r+FuU8/M9sc/X2P/7xkZvuY+/Qzsw9E/8b7qpndE/3bb6B/1hMedYCZZST9kaQfk/QmSbeY2Zu6Oyq02f+WdEPdsXFJn3f3N0r6fHRbqn4fvDH68z5Jf9yhMWJ1nJf0QXf/fknbJb0/+vvN/KfbK5J2ufvVkrZKusHMtkv6LUl3RvN+VtLPRef/nKSz7v69ku6MzkN/+2VJj9XcZu4Hx0533+ruo9Ft3u8Hw+9J+lt3v1LS1ar+/WfuU87dn4j+vm+VdK2kGUmfFnOfamZWkPRLkkbd/QclZSS9WwP+s57wqDPeLOnr7v5Ndz8n6f9KurHLY0IbufsXJL1Qd/hGSX8Wff5nksZqjv+5Vx2TlDez13RmpGg3d3/O3R+JPv93Vf8xWRDzn2rR/P1HdDMb/XFJuyR9KjpeP+/x98OnJL3NzKxDw0WbmdkVkvZI+nh028TcDzLe71POzP6TpB+R9AlJcvdz7l4Scz9o3ibpG+7+tJj7QTAsKWdmw5JGJD2nAf9ZT3jUGQVJ/1pz+9noGNLt1e7+nFQNGCR9d3Sc74eUikpUt0n6opj/1IuWLZ2Q9Lykz0n6hqSSu5+PTqmd2/l5j+5/UdLlnR0x2uhjkn5N0lx0+3Ix94PCJf2dmR03s/dFx3i/T783SDoj6U+j5aofN7O1Yu4Hzbsl3RN9ztynmLsXJf22pGdUDY1elHRcA/6znvCoM5JSR+/4KNAr+H5IITO7RNIDkva5+0uNTk04xvz3IXefjcrYr1C1wvT7k06LPjLvKWFm75D0vLsfrz2ccCpzn0473P0aVZemvN/MfqTBucx9egxLukbSH7v7Nkkv68IypSTMfcpEvW1+QtL9S52acIy57zNRD6sbJW2StEHSWlXf9+sN1M96wqPOeFbSa2tuXyHpdJfGgs75VlymGn18PjrO90PKmFlW1eDobnd/MDrM/A+IaOnCP6ja8yoflTdLC+d2ft6j+9dp8VJX9Icdkn7CzJ5SdRn6LlUrkZj7AeDup6OPz6va9+TN4v1+EDwr6Vl3/2J0+1OqhknM/eD4MUmPuPu3otvMfbq9XdKT7n7G3SuSHpT0wxrwn/WER53xZUlvjLqzX6RqyeNDXR4TVt9Dkt4bff5eSX9Vc/xnot0Ytkt6MS57Rf+J1jN/QtJj7v67NXcx/ylmZuvNLB99nlP1HxmPSToi6abotPp5j78fbpJ02N1T9xupQeDut7n7Fe7+elV/nh9291vF3Keema01s++KP5d0vaSvivf71HP3/yfpX81sc3TobZL+Wcz9ILlFF5asScx92j0jabuZjUT/1o//zg/0z3pL4dfUk8zsx1X9zWRG0ifd/Te7PCS0kZndI+k6Sa+S9C1Jt0ualHSfpI2qvgH9pLu/EL0B/aGqu7PNSPpZd5/qxrixcmb2Vkn/KOmULvQ/+Q1V+x4x/yllZlep2hgxo+ovYu5z94+Y2RtUrUa5TNK0pPe4+ytmtkbSX6jaE+sFSe929292Z/RoFzO7TtKvuvs7mPv0i+b409HNYUl/6e6/aWaXi/f71DOzrao2yb9I0jcl/ayi938x96lmZiOq9rN5g7u/GB3j733KmdmHJd2s6s7K05J+XtXeRgP7s57wCAAAAAAAAEEsWwMAAAAAAEAQ4REAAAAAAACCCI8AAAAAAAAQRHgEAAAAAACAIMIjAAAAAAAABBEeAQCA1DOzV5vZX5rZN83suJn9k5m9M7rvOjP7zBLX32Fmv9ric/5HC+fui7aDBgAA6DmERwAAINXMzCRNSvqCu7/B3a+V9G5JV3R3ZAvsk0R4BAAAehLhEQAASLtdks65+5/EB9z9aXf/g/oTzewyM5s0s6+Y2TEzu6rm7qvN7LCZ/YuZ/UJ0/iVm9nkze8TMTpnZjY0GYmZrzeyQmZ00s6+a2c1m9kuSNkg6YmZHovOuj6qjHjGz+83skuj4U2b2W2b2pejP96785QEAAGhsuNsDAAAAWGU/IOmRJs/9sKRpdx8zs12S/lzS1ui+qyRtl7RW0rSZHZL0vKR3uvtLZvYqScfM7CF398Dj3yDptLvvkSQzW+fuL5rZr0ja6e7fjh7nQ5Le7u4vm9mvS/oVSR+JHuMld3+zmf2MpI9JekfzLwUAAEDrqDwCAAADxcz+KKr8+XLC3W+V9BeS5O6HJV1uZuui+/7K3cvu/m1JRyS9WZJJ+l9m9hVJfy+pIOnVDZ7+lKS3R9VD/9ndX0w4Z7ukN0k6amYnJL1X0utq7r+n5uNbmviSAQAAVoTKIwAAkHaPSnpXfMPd3x9V90wlnGsJx7zuY+3xWyWtl3Stu1fM7ClJa0IDcfevmdm1kn5c0gEz+zt3/0jdaSbpc+5+S+hhAp8DAACsCiqPAABA2h2WtMbM/nvNsVBz6i+oGgjJzK6T9G13fym670YzW2Nml0u6TtKXJa2T9HwUHO3UwgqhRcxsg6QZd/8/kn5b0jXRXf8u6buiz49J2hH3MzKzETP7vpqHubnm4z81ej4AAIB2oPIIAACkmru7mY1JutPMfk3SGUkvS/r1hNPvkPSn0TK0GVWXjMW+JOmQpI2S/qe7nzazuyX9tZlNSToh6fElhrNF0kEzm5NUkRQHWndJ+hsze87dd5rZf5N0j5ldHN3/IUlfiz6/2My+qOovAUPVSQAAAG1j4X6OAAAA6CXRsrjRqO8SAABAR7BsDQAAAAAAAEFUHgEAAAAAACCIyiMAAAAAAAAEER4BAAAAAAAgiPAIAAAAAAAAQYRHAAAAAAAACCI8AgAAAAAAQND/B0JsyEdabIBvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: GO Hi this is Jaemin . . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: GO Nice to meet you too ! ! ! !\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: GO I like Python . . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: GO Bye Bye . . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: GO I live in Seoul , South Korea . .\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: GO I study industrial engineering . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir_seqepoch_801\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: GO Beer please ! ! ! ! ! ! !\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: GO Leffe brown ! ! ! ! ! ! !\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = seq2seqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_path+'epoch_'+str(model.n_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.randint(1, high=22, size=[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 13, 11,  1, 16,  9, 17,  6,  8,  5, 10, 10, 13,  7,  7, 16, 19,\n",
       "       15,  3, 18,  7, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x has shape [2, 3, 2]\n",
    "x = tf.constant([[[1., 2.], [3., 4. ], [5. , 6. ]],\n",
    "                 [[7., 8.], [9., 10.], [11., 12.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3), Dimension(2)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_1:0' shape=(2, 2) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.]],\n",
       "\n",
       "       [[ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  4.],\n",
       "       [ 9., 10.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1,:].eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2.]],\n",
       "\n",
       "       [[7., 8.]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(x,[0,0,0],[-1,1,2]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.constant(np.reshape(test,(2,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.slice(y,[0,0],[-1,8]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file('spa-eng.zip', \n",
    "                                      origin='http://download.tensorflow.org/data/spa-eng.zip', \n",
    "    extract=True)\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "class LanguageIndex():\n",
    "    def __init__(self, lang):\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        self.create_index()\n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "          self.vocab.update(phrase.split(' '))\n",
    "    \n",
    "        self.vocab = sorted(self.vocab)\n",
    "    \n",
    "        self.word2idx['<pad>'] = 0\n",
    "        for index, word in enumerate(self.vocab):\n",
    "          self.word2idx[word] = index + 1\n",
    "    \n",
    "        for word, index in self.word2idx.items():\n",
    "          self.idx2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples):\n",
    "    # creating cleaned input, output pairs\n",
    "    pairs = create_dataset(path, num_examples)\n",
    "    \n",
    "    # index language using the class defined above    \n",
    "    inp_lang = LanguageIndex(sp for en, sp in pairs)\n",
    "    targ_lang = LanguageIndex(en for en, sp in pairs)\n",
    "    \n",
    "    # Vectorize the input and target languages\n",
    "    \n",
    "    # Spanish sentences\n",
    "    input_tensor = [[inp_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
    "    \n",
    "    # English sentences\n",
    "    target_tensor = [[targ_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
    "    \n",
    "    # Calculate max_length of input and output tensor\n",
    "    # Here, we'll set those to the longest sentence in the dataset\n",
    "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "    \n",
    "    # Padding the input and output tensor to the maximum length\n",
    "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor,\n",
    "                                                                maxlen=max_length_inp,\n",
    "                                                                padding='post')\n",
    "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor,\n",
    "                                                                 maxlen=max_length_tar,\n",
    "                                                                 padding='post')\n",
    "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 3000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(path_to_file, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 2400, 600, 600)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tf.data dataset\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.map(lambda x,y:(x,y, tf.size(x), tf.size(y)))\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_encoder = tf.get_variable('embedding_enc',shape=(vocab_inp_size,embedding_dim), \n",
    "                             initializer=tf.random_uniform_initializer)\n",
    "embeddings_decoder = tf.get_variable('embedding_dec',shape=(vocab_tar_size,embedding_dim), \n",
    "                             initializer=tf.random_uniform_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(encode_input_emb):\n",
    "    with tf.variable_scope('encode',reuse=tf.AUTO_REUSE):\n",
    "        encoder_cell= tf.nn.rnn_cell.BasicLSTMCell(units)\n",
    "        encoder_cell = tf.nn.rnn_cell.DropoutWrapper(encoder_cell,input_keep_prob=1, output_keep_prob=0.5)\n",
    "        enc_out, enc_state = tf.nn.dynamic_rnn(encoder_cell,encode_input_emb,dtype=tf.float32)\n",
    "    return enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(decode_input_emb, initiale_state):\n",
    "    with tf.variable_scope('decode',reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        decoder_cell= tf.nn.rnn_cell.BasicLSTMCell(units)\n",
    "        decoder_cell= tf.nn.rnn_cell.DropoutWrapper(decoder_cell,input_keep_prob=1,output_keep_prob=0.5)\n",
    "        dec_out, dec_state = tf.nn.dynamic_rnn(decoder_cell,decode_input_emb,\n",
    "                                               initial_state=initiale_state,dtype=tf.float32)\n",
    "        dec_output = tf.layers.dense(dec_out,vocab_tar_size)\n",
    "    return dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq(encode_input_emb,decode_input_emb,enc_size):\n",
    "    enc_state = encode(tf.nn.embedding_lookup(embeddings_encoder,enc_inp))\n",
    "    dec_output = decode(tf.nn.embedding_lookup(embeddings_decoder,decode_input_emb),enc_state)\n",
    "    print('final',tf.shape(dec_output))\n",
    "    return dec_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(dec_inp,logit):\n",
    "    with tf.variable_scope('loss',reuse=tf.AUTO_REUSE):\n",
    "        mask = 1 - np.equal(enc_inp, 0)\n",
    "        #print('shape',tf.shape(pred))\n",
    "        #print('target', enc_inp.shape)\n",
    "        #logit = seq2seq(enc_inp,dec_inp,enc_size)\n",
    "        loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dec_inp, logits=logit)\n",
    "        loss1_= loss_*mask\n",
    "    return tf.reduce_mean(loss1_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "enc_inp, dec_inp ,enc_size, dec_size = iterator.get_next()\n",
    "\n",
    "with tf.variable_scope('adam1', reuse=tf.AUTO_REUSE):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "    #loss1 = loss_function(dec_inp, logit)\n",
    "    #loss_op = optimizer.minimize(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "loss after 0 epoch is 2.406315326690674\n",
      "accuracy after 0 epoch is 0.5703125\n",
      "loss after 1 epoch is 2.109083652496338\n",
      "accuracy after 1 epoch is 0.64453125\n",
      "loss after 2 epoch is 1.890817403793335\n",
      "accuracy after 2 epoch is 0.6953125\n",
      "loss after 3 epoch is 1.951646327972412\n",
      "accuracy after 3 epoch is 0.62890625\n",
      "loss after 4 epoch is 1.6667754650115967\n",
      "accuracy after 4 epoch is 0.75390625\n",
      "loss after 5 epoch is 1.6484253406524658\n",
      "accuracy after 5 epoch is 0.72265625\n",
      "loss after 6 epoch is 1.5828717947006226\n",
      "accuracy after 6 epoch is 0.72265625\n",
      "loss after 7 epoch is 1.484752893447876\n",
      "accuracy after 7 epoch is 0.75390625\n",
      "loss after 8 epoch is 1.3398027420043945\n",
      "accuracy after 8 epoch is 0.7578125\n",
      "loss after 9 epoch is 1.4076335430145264\n",
      "accuracy after 9 epoch is 0.7890625\n",
      "loss after 10 epoch is 1.3415203094482422\n",
      "accuracy after 10 epoch is 0.76953125\n",
      "loss after 11 epoch is 1.208390235900879\n",
      "accuracy after 11 epoch is 0.82421875\n",
      "loss after 12 epoch is 1.088378667831421\n",
      "accuracy after 12 epoch is 0.8203125\n",
      "loss after 13 epoch is 1.128440499305725\n",
      "accuracy after 13 epoch is 0.81640625\n",
      "loss after 14 epoch is 1.0243895053863525\n",
      "accuracy after 14 epoch is 0.83984375\n",
      "loss after 15 epoch is 1.1292022466659546\n",
      "accuracy after 15 epoch is 0.8359375\n",
      "loss after 16 epoch is 1.0109939575195312\n",
      "accuracy after 16 epoch is 0.84765625\n",
      "loss after 17 epoch is 1.0023120641708374\n",
      "accuracy after 17 epoch is 0.8359375\n",
      "loss after 18 epoch is 0.9613937139511108\n",
      "accuracy after 18 epoch is 0.8515625\n",
      "loss after 19 epoch is 0.819680392742157\n",
      "accuracy after 19 epoch is 0.85546875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x241ab3b3978>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit = seq2seq(enc_inp,dec_inp,enc_size)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logit,axis=-1), tf.cast(dec_inp,tf.int64)),tf.float32))\n",
    "#test_val = tf.argmax(logit,axis=1)\n",
    "#test_valN1 = tf.argmax(logit,axis=-1)\n",
    "loss1 = loss_function(dec_inp, logit)\n",
    "gradients = optimizer.compute_gradients(loss1)\n",
    "capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "train_op = optimizer.apply_gradients(capped_gradients)\n",
    "#loss_op = optimizer.minimize(loss1)\n",
    "losses = []\n",
    "#last_val = None\n",
    "#last_val_axisN1 = None\n",
    "#last_logit = None\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer()])\n",
    "    for epoc in range(20):\n",
    "        #train_op = seq2seq(enc_inp,dec_inp,enc_size )\n",
    "        #print(enc_inp.shape)\n",
    "        #dec_output = sess.run([train_op])\n",
    "        #print(tf.sqnp.array(dec_output))\n",
    "        #print('Shape ',tf.convert_to_tensor(np.array(dec_output)))\n",
    "        #dec_output = np.array(dec_output)\n",
    "        #print(tf.squeeze(dec_output))\n",
    "        #print(tf.shape(tf.nn.embedding_lookup(embeddings_decoder,dec_inp)).eval())\n",
    "        sess.run(iterator.initializer)\n",
    "        total_loss=0\n",
    "        try:\n",
    "            while True:\n",
    "                #print(dec_inp.eval())\n",
    "                _,loss_val,acc = sess.run([train_op,loss1,accuracy])\n",
    "                #print(testval.shape)\n",
    "                total_loss +=loss_val\n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print('loss after {0} epoch is {1}'.format(epoc,loss_val))\n",
    "        print('accuracy after {0} epoch is {1}'.format(epoc,acc))\n",
    "        #print(testval)\n",
    "        #last_val = testval\n",
    "        #last_val_axisN1 = testvalN\n",
    "        #last_logit = logitlast\n",
    "        losses.append(total_loss)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_val_axisN1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(last_logit[0,2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(last_logit,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tar_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (batch,(enc_inp, dec_inp ,enc_size, dec_size)) in enumerate(dataset):\n",
    "    #train_op = seq2seq(enc_inp,dec_inp,enc_size )\n",
    "   \n",
    "    #print('predictions',train_op.shape)\n",
    "    #print('real',dec_inp.shape)\n",
    "    #mask = 1-np.equal(train_op, 0)\n",
    "    #loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=dec_inp,logits=np.array(train_op))*mask\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "    variables = tf.trainable_variables()\n",
    "    \n",
    "    loss_= loss_function(dec_inp, dec_inp,enc_size)\n",
    "    var_grad = optimizer.compute_gradients(loss_,variables)\n",
    "    optimizer.apply_gradients(var_grad)\n",
    "    print(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "T=tf.constant([[[10,11,12],[13,14,15]],\n",
    "[[16,17,18],[19,20,21]],\n",
    "[[22,23,24],[25,26,27]]])\n",
    "sess=tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=tf.slice(T,[0,1,1],[1,1,2])\n",
    "print(S.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[10,11,12],[13,14,15]],\n",
    "[[16,17,18],[19,20,21]],\n",
    "[[22,23,24],[25,26,27]],\n",
    "             [[0,0,0],[0,0,0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-np.equal(a,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*(1-np.equal(a,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
